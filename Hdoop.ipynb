{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.docker.com/docker-for-windows/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Docker Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box required for 6250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker run -it --privileged=true \\\n",
    "  --cap-add=SYS_ADMIN \\\n",
    "  -m 8192m -h bootcamp.local \\\n",
    "  --name bigbox -p 2222:22 -p 9530:9530 -p 8888:8888\\\n",
    "  -v ~/Downloads/homework2:/r oot/homework2/ \\\n",
    "  sunlab/bigbox:latest \\\n",
    "  /bin/bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Basicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker kill <instance Id>  # stop running instance\n",
    "# docker rm <instance Id>    # remove running instance\n",
    "# docker ps -a               # display all instance(running and stopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/scripts/start-services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New User root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####hadoop default user is hdfs\n",
    "###login as hdfs to create new user matching docker default user root \n",
    "#sudo su - hdfs \n",
    "\n",
    "#hdfs dfs -mkdir -p /user/root\n",
    "#hdfs dfs -chown root /user/root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make input folder and put/get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdfs dfs -mkdir input\n",
    "\n",
    "### change folder input owner to root\n",
    "#hdfs dfs -chown root input\n",
    "\n",
    "\n",
    "#hdfs dfs -put case.csv input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark bug during running hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment the following lines as follows in /usr/lib/hive/bin/hive\n",
    "### Hint: use command \"vi /usr/lib/hive/bin/hive\"\n",
    "\n",
    "# add Spark assembly jar to the classpath\n",
    "#if [[ -n \"$SPARK_HOME\" ]]\n",
    "#then\n",
    "#  sparkAssemblyPath=`ls ${SPARK_HOME}/lib/spark-assembly-*.jar`\n",
    "#  CLASSPATH=\"${CLASSPATH}:${sparkAssemblyPath}\"\n",
    "#fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exit hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctrl/cmd + C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Table and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE events (\n",
    "#         patient_id STRING,\n",
    "#         event_name STRING,\n",
    "#         date_offset INT,\n",
    "#         value INT)\n",
    "#       ROW FORMAT DELIMITED\n",
    "#       FIELDS TERMINATED BY ','\n",
    "#       STORED AS TEXTFILE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD DATA LOCAL INPATH /root/homework2/events.csv OVERWRITE INTO TABLE events;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount data into your docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -it --privileged=true \\\n",
    "#   --cap-add=SYS_ADMIN \\\n",
    "#   -m 8192m -h abootcamp.local \\\n",
    "#   --name bigbox -p 2222:22 -p 9530:9530 -p 8888:8888\\\n",
    "#   -v /:/mnt/host \\\n",
    "#   sunlab/bigbox:latest \\\n",
    "#   --mount type=bind,source=\"$(pwd)\"/homework2,target=/root/homework2 \\\n",
    "#   /bin/bash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo su - hdfs\n",
    "hdfs dfs -mkdir -p /data\n",
    "hdfs dfs -chown -R root /data\n",
    "exit\n",
    "hdfs dfs -put /root/homework2/data/* /data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
